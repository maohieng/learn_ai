{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Text Generation on Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 1161192\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK Brown Corpus\n",
    "nltk.download('brown')\n",
    "\n",
    "# Combine all words into a single string\n",
    "# corpus = ' '.join(brown.words())\n",
    "# print('Corpus length:', len(corpus))\n",
    "words = brown.words()\n",
    "print('Number of words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length: 812834\n",
      "Validation data length: 116119\n",
      "Test data length: 232239\n",
      "['dissolve', 'the', 'an', 'spite', 'of', 'other', 'work', 'full', '.', 'accept']\n"
     ]
    }
   ],
   "source": [
    "# Split the corpus into training (70%), validation (10%), and test (20%) sets\n",
    "train_data, tmp_data = train_test_split(words, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(tmp_data, test_size=2/3, random_state=42)\n",
    "\n",
    "print('Train data length:', len(train_data))\n",
    "print('Validation data length:', len(val_data))\n",
    "print('Test data length:', len(test_data))\n",
    "print(train_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common tokens: ['knowledge', 'jump', 'disapproval', 'sharply', 'lion', 'Act', 'odor', 'deaf', 'road', 'spread']\n"
     ]
    }
   ],
   "source": [
    "# Limit the vocabulary size to the 7000 most common words\n",
    "vocab_size = 7000\n",
    "train_counter = Counter(train_data)\n",
    "most_common_tokens = {word for word, _ in train_counter.most_common(vocab_size)}\n",
    "\n",
    "print('Most common tokens:', list(most_common_tokens)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite replace_rare_tokens function using simple loop\n",
    "def replace_rare_tokens(data, most_common_tokens):\n",
    "    result = []\n",
    "    for word in data:\n",
    "        if word in most_common_tokens:\n",
    "            result.append(word)\n",
    "        else:\n",
    "            result.append('<UNK>')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training tokens: ['<UNK>', 'the', 'an', 'spite', 'of', 'other', 'work', 'full', '.', 'accept']\n",
      "Sample validation tokens: ['a', 'defense', 'appropriate', 'by', 'can', 'not', 'should', 'manner', 'He', 'films']\n",
      "Sample test tokens: ['<UNK>', 'used', 'I', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '.', '?', 'now']\n"
     ]
    }
   ],
   "source": [
    "train_tokens_limited = replace_rare_tokens(train_data, most_common_tokens)\n",
    "val_tokens_limited = replace_rare_tokens(val_data, most_common_tokens)\n",
    "test_tokens_limited = replace_rare_tokens(test_data, most_common_tokens)\n",
    "\n",
    "print(\"Sample training tokens:\", train_tokens_limited[:10])\n",
    "print(\"Sample validation tokens:\", val_tokens_limited[:10])\n",
    "print(\"Sample test tokens:\", test_tokens_limited[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tokens length: 812834\n",
      "Validation tokens length: 116119\n",
      "Test tokens length: 232239\n"
     ]
    }
   ],
   "source": [
    "print(\"Train tokens length:\", len(train_tokens_limited))\n",
    "print(\"Validation tokens length:\", len(val_tokens_limited))\n",
    "print(\"Test tokens length:\", len(test_tokens_limited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate n-grams\n",
    "def generate_ngrams(tokens, n):\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1-gram: [(1,), (2,), (3,), (4,), (5,)]\n",
      "Test 2-gram: [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "Test 3-gram: [(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n",
      "Test 4-gram: [(1, 2, 3, 4), (2, 3, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "# Test generate_ngrams function\n",
    "test_tokens = [1, 2, 3, 4, 5]\n",
    "for i in range (1, 5):\n",
    "    ngrams = generate_ngrams(test_tokens, i)\n",
    "    print(f\"Test {i}-gram:\", ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Language Model 1: Backoff Method without Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def l1_train(tokens, n):\n",
    "    ngram_counts = defaultdict(Counter)\n",
    "    context_counts = Counter()\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        ngrams = generate_ngrams(tokens, i)\n",
    "        for ngram in ngrams:\n",
    "            ngram_counts[len(ngram)][ngram] += 1\n",
    "            context_counts[ngram[:-1]] += 1\n",
    "\n",
    "    return ngram_counts, context_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities without smoothing\n",
    "def l1_probability(ngram_counts, context_counts, ngram):\n",
    "    for i in range(len(ngram), 0, -1):\n",
    "        if ngram[-i:] in ngram_counts[i]:\n",
    "            return ngram_counts[i][ngram[-i:]] / context_counts[ngram[-i:-1]]\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "train_ngram_counts, train_context_counts = l1_train(train_tokens_limited, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train n-gram counts: 233353\n",
      "Train context counts: 233353\n"
     ]
    }
   ],
   "source": [
    "print(\"Train n-gram counts:\", train_ngram_counts[1][('i',)])\n",
    "print(\"Train context counts:\", train_context_counts[('i',)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of (' ', ' '): 0.1892496649135914\n"
     ]
    }
   ],
   "source": [
    "test_l1 = (' ', ' ')\n",
    "print(f\"Probability of {test_l1}: {l1_probability(train_ngram_counts, train_context_counts, test_l1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621\n"
     ]
    }
   ],
   "source": [
    "test2_l1 = train_ngram_counts[4][(' ', ' ', ' ', ' ')]\n",
    "print(test2_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a generic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.ngram_counts = defaultdict(Counter)\n",
    "        self.context_counts = Counter()\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def train(self, tokens):\n",
    "        self.vocab_size = len(set(tokens))\n",
    "        for i in range(1, self.n+1):\n",
    "            ngrams = generate_ngrams(tokens, i)\n",
    "            for ngram in ngrams:\n",
    "                self.ngram_counts[len(ngram)][ngram] += 1\n",
    "                self.context_counts[ngram[:-1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff_no_smooth_prob(model, target):\n",
    "    for i in range(len(target), 0, -1):\n",
    "        if target[-i:] in model.ngram_counts[i]:\n",
    "            count = model.ngram_counts[i][target[-i:]]\n",
    "            context_count = model.context_counts[target[-i:-1]]\n",
    "            return count / context_count\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LanguageModel(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.train(train_tokens_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00014886188323815194\n"
     ]
    }
   ],
   "source": [
    "test_prob = backoff_no_smooth_prob(model1, ('happy', 'new', 'year', 'coming'))\n",
    "print(test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_prob(model, ngram, lambdas, k=1):\n",
    "    prob = 0\n",
    "    for i in range(len(ngram), 0, -1):\n",
    "        count = model.ngram_counts[i][ngram[-i:]]\n",
    "        context_count = model.context_counts[ngram[-i:-1]]\n",
    "        prob += lambdas[i-1] * (count + k) / (context_count + k * model.vocab_size)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambdas = [0.1, 0.2, 0.3, 0.4]\n",
    "best_k = 0.1\n",
    "\n",
    "p2 = interpolation_prob(model1, ('happy', 'new', 'year', 'coming'), best_lambdas, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001326792394096378\n"
     ]
    }
   ],
   "source": [
    "print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_backoff_perplexity(model, tokens, n):\n",
    "    ngrams = generate_ngrams(tokens, n)\n",
    "    log_prob_sum = 0\n",
    "    for ngram in ngrams:\n",
    "        prob = backoff_no_smooth_prob(model, ngram)\n",
    "        log_prob_sum += np.log(prob + 1e-12)  # Avoid log(0) by adding a small constant\n",
    "    perplexity = np.exp(-log_prob_sum / len(ngrams))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backoff no smoothing perplexity: 343.16806395156556\n"
     ]
    }
   ],
   "source": [
    "l1_perplexity = compute_backoff_perplexity(model1, val_tokens_limited, 4)\n",
    "print(\"Backoff no smoothing perplexity:\", l1_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_interpolation_perplexity(model, tokens, n, lambdas, k):\n",
    "    ngrams = generate_ngrams(tokens, n)\n",
    "    log_prob_sum = 0\n",
    "    for ngram in ngrams:\n",
    "        prob = interpolation_prob(model, ngram, lambdas, k)\n",
    "        log_prob_sum += np.log(prob + 1e-12)  # Avoid log(0) by adding a small constant\n",
    "    perplexity = np.exp(-log_prob_sum / len(ngrams))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation perplexity: 825.2702442649656\n"
     ]
    }
   ],
   "source": [
    "print(\"Interpolation perplexity:\", compute_interpolation_perplexity(model1, val_tokens_limited, 4, best_lambdas, best_k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
