{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CS75Sz_zQPm",
        "outputId": "eebd7d6f-e22c-4fe8-ee62-748b03643615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 3)\n",
            "x (30, 2)\n",
            "y (30,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = '/content/land_price_1.csv'\n",
        "\n",
        "data = pd.read_csv(path).to_numpy()\n",
        "print(data.shape)\n",
        "\n",
        "x = data[:, :-1] #np(m, 2)\n",
        "y = data[:, -1]\n",
        "print('x', x.shape)\n",
        "print('y', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling\n",
        "def feature_scaling(x):\n",
        "  mu = np.mean(x, axis=0) #np(n)\n",
        "  x = (x-mu)/(np.max(x, axis=0)-np.min(x, axis=0))\n",
        "  return x\n",
        "\n",
        "x_scaled = feature_scaling(x)\n",
        "x_scaled = np.concatenate((np.ones((x_scaled.shape[0], 1)), x_scaled), axis=1)\n",
        "print(x_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT04jS2U8A3a",
        "outputId": "05608234-cbf3-49c4-f39d-fc4bf6fd4bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "import torch\n",
        "\n",
        "theta = torch.zeros(3, dtype=torch.float32) #tensor(3)\n",
        "theta.requires_grad = True\n",
        "alpha = 0.1\n",
        "\n",
        "tx = torch.tensor(x_scaled, dtype=torch.float32) #tensor(30, 3)\n",
        "ty = torch.tensor(y, dtype=torch.float32) #tensor(30)\n",
        "\n",
        "for i in range(1000):\n",
        "  tz = torch.matmul(tx, theta.reshape(-1, 1)).flatten() #tensor(30)\n",
        "  J = torch.mean((tz-ty)**2)\n",
        "\n",
        "  if i%10==0:\n",
        "    print('i: %d, J: %f' % (i, J.item()))\n",
        "\n",
        "  J.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    theta += -alpha*theta.grad\n",
        "    theta.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFEWkYPo6cGb",
        "outputId": "4cfc9d40-72eb-4498-ea9b-86bb5bc4121f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i: 0, J: 35052.921875\n",
            "i: 10, J: 5749.137207\n",
            "i: 20, J: 3747.741211\n",
            "i: 30, J: 2584.124023\n",
            "i: 40, J: 1787.138550\n",
            "i: 50, J: 1238.518066\n",
            "i: 60, J: 860.068176\n",
            "i: 70, J: 598.468750\n",
            "i: 80, J: 417.274139\n",
            "i: 90, J: 291.518646\n",
            "i: 100, J: 204.067413\n",
            "i: 110, J: 143.135239\n",
            "i: 120, J: 100.600060\n",
            "i: 130, J: 70.852974\n",
            "i: 140, J: 50.011990\n",
            "i: 150, J: 35.385471\n",
            "i: 160, J: 25.103333\n",
            "i: 170, J: 17.863827\n",
            "i: 180, J: 12.758795\n",
            "i: 190, J: 9.153728\n",
            "i: 200, J: 6.604446\n",
            "i: 210, J: 4.799315\n",
            "i: 220, J: 3.519610\n",
            "i: 230, J: 2.611263\n",
            "i: 240, J: 1.965816\n",
            "i: 250, J: 1.506755\n",
            "i: 260, J: 1.179922\n",
            "i: 270, J: 0.947002\n",
            "i: 280, J: 0.780881\n",
            "i: 290, J: 0.662315\n",
            "i: 300, J: 0.577650\n",
            "i: 310, J: 0.517132\n",
            "i: 320, J: 0.473844\n",
            "i: 330, J: 0.442865\n",
            "i: 340, J: 0.420686\n",
            "i: 350, J: 0.404799\n",
            "i: 360, J: 0.393405\n",
            "i: 370, J: 0.385237\n",
            "i: 380, J: 0.379388\n",
            "i: 390, J: 0.375179\n",
            "i: 400, J: 0.372165\n",
            "i: 410, J: 0.370002\n",
            "i: 420, J: 0.368446\n",
            "i: 430, J: 0.367329\n",
            "i: 440, J: 0.366531\n",
            "i: 450, J: 0.365953\n",
            "i: 460, J: 0.365540\n",
            "i: 470, J: 0.365241\n",
            "i: 480, J: 0.365025\n",
            "i: 490, J: 0.364867\n",
            "i: 500, J: 0.364758\n",
            "i: 510, J: 0.364678\n",
            "i: 520, J: 0.364622\n",
            "i: 530, J: 0.364580\n",
            "i: 540, J: 0.364551\n",
            "i: 550, J: 0.364528\n",
            "i: 560, J: 0.364511\n",
            "i: 570, J: 0.364500\n",
            "i: 580, J: 0.364492\n",
            "i: 590, J: 0.364486\n",
            "i: 600, J: 0.364483\n",
            "i: 610, J: 0.364479\n",
            "i: 620, J: 0.364477\n",
            "i: 630, J: 0.364477\n",
            "i: 640, J: 0.364478\n",
            "i: 650, J: 0.364477\n",
            "i: 660, J: 0.364473\n",
            "i: 670, J: 0.364473\n",
            "i: 680, J: 0.364477\n",
            "i: 690, J: 0.364470\n",
            "i: 700, J: 0.364473\n",
            "i: 710, J: 0.364470\n",
            "i: 720, J: 0.364472\n",
            "i: 730, J: 0.364473\n",
            "i: 740, J: 0.364474\n",
            "i: 750, J: 0.364475\n",
            "i: 760, J: 0.364470\n",
            "i: 770, J: 0.364471\n",
            "i: 780, J: 0.364469\n",
            "i: 790, J: 0.364476\n",
            "i: 800, J: 0.364474\n",
            "i: 810, J: 0.364477\n",
            "i: 820, J: 0.364476\n",
            "i: 830, J: 0.364476\n",
            "i: 840, J: 0.364476\n",
            "i: 850, J: 0.364476\n",
            "i: 860, J: 0.364476\n",
            "i: 870, J: 0.364476\n",
            "i: 880, J: 0.364476\n",
            "i: 890, J: 0.364476\n",
            "i: 900, J: 0.364476\n",
            "i: 910, J: 0.364476\n",
            "i: 920, J: 0.364476\n",
            "i: 930, J: 0.364476\n",
            "i: 940, J: 0.364476\n",
            "i: 950, J: 0.364476\n",
            "i: 960, J: 0.364476\n",
            "i: 970, J: 0.364476\n",
            "i: 980, J: 0.364476\n",
            "i: 990, J: 0.364476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model\n",
        "tz = torch.matmul(tx, theta.reshape(-1, 1)).flatten()\n",
        "z = tz.detach().numpy()\n",
        "\n",
        "for i, (zi, yi) in enumerate(zip(z, y)):\n",
        "  print('i: %02d, predict: %f, real: %f' % (i+1, zi, yi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvDV-2M-O3S",
        "outputId": "4e77a102-9f70-4fd5-bbbd-4d6bbe769a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i: 01, predict: 16.194910, real: 15.700000\n",
            "i: 02, predict: 10.244612, real: 11.300000\n",
            "i: 03, predict: 41.954441, real: 42.000000\n",
            "i: 04, predict: 35.082279, real: 35.000000\n",
            "i: 05, predict: 38.084732, real: 37.700000\n",
            "i: 06, predict: 75.442169, real: 75.500000\n",
            "i: 07, predict: 77.723839, real: 77.100000\n",
            "i: 08, predict: 89.345947, real: 88.700000\n",
            "i: 09, predict: 121.073875, real: 122.000000\n",
            "i: 10, predict: 118.729263, real: 119.100000\n",
            "i: 11, predict: 126.542435, real: 125.600000\n",
            "i: 12, predict: 145.399796, real: 145.500000\n",
            "i: 13, predict: 149.603668, real: 150.000000\n",
            "i: 14, predict: 145.948059, real: 145.000000\n",
            "i: 15, predict: 171.646469, real: 172.000000\n",
            "i: 16, predict: 169.267136, real: 170.000000\n",
            "i: 17, predict: 176.384842, real: 177.000000\n",
            "i: 18, predict: 170.028763, real: 169.400000\n",
            "i: 19, predict: 210.511993, real: 211.000000\n",
            "i: 20, predict: 219.907730, real: 220.000000\n",
            "i: 21, predict: 231.125534, real: 231.400000\n",
            "i: 22, predict: 216.739273, real: 216.900000\n",
            "i: 23, predict: 228.558121, real: 227.500000\n",
            "i: 24, predict: 239.063812, real: 239.400000\n",
            "i: 25, predict: 243.963837, real: 244.300000\n",
            "i: 26, predict: 280.230194, real: 279.800000\n",
            "i: 27, predict: 258.878082, real: 259.500000\n",
            "i: 28, predict: 295.313690, real: 295.400000\n",
            "i: 29, predict: 315.405762, real: 314.100000\n",
            "i: 30, predict: 324.204071, real: 324.700000\n"
          ]
        }
      ]
    }
  ]
}