{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUYaYBHSBQyb",
        "outputId": "4bdf6382-7a35-4885-e62e-8c9a316218cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (20000, 784)\n",
            "y (20000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/sample_data/mnist_train_small.csv', header=None).to_numpy()\n",
        "\n",
        "x = data[:, 1:]\n",
        "y = data[:, 0]\n",
        "\n",
        "print('x', x.shape)\n",
        "print('y', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset, DataLoader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SmallMNIST(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    tx = torch.tensor(self.x[idx], dtype=torch.float32)\n",
        "    ty = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "    return tx, ty\n",
        "\n",
        "ds = SmallMNIST(x, y)\n",
        "print('num samples:', len(ds))\n",
        "\n",
        "loader = DataLoader(ds, batch_size=3000, shuffle=True)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for i, (bx, by) in enumerate(loader):\n",
        "    print('Epoch: %d, Iter: %d, Mini-batch Size: %d' % (epoch, i, bx.shape[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiBWo4V7Ctzb",
        "outputId": "910548a0-70af-42b3-eeb0-a6a691c1a088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num samples: 20000\n",
            "Epoch: 0, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 0, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 0, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 0, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 0, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 0, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 0, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 1, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 1, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 1, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 1, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 1, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 1, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 1, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 2, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 2, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 2, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 2, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 2, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 2, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 2, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 3, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 3, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 3, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 3, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 3, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 3, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 3, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 4, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 4, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 4, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 4, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 4, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 4, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 4, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 5, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 5, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 5, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 5, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 5, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 5, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 5, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 6, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 6, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 6, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 6, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 6, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 6, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 6, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 7, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 7, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 7, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 7, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 7, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 7, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 7, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 8, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 8, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 8, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 8, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 8, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 8, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 8, Iter: 6, Mini-batch Size: 2000\n",
            "Epoch: 9, Iter: 0, Mini-batch Size: 3000\n",
            "Epoch: 9, Iter: 1, Mini-batch Size: 3000\n",
            "Epoch: 9, Iter: 2, Mini-batch Size: 3000\n",
            "Epoch: 9, Iter: 3, Mini-batch Size: 3000\n",
            "Epoch: 9, Iter: 4, Mini-batch Size: 3000\n",
            "Epoch: 9, Iter: 5, Mini-batch Size: 3000\n",
            "Epoch: 9, Iter: 6, Mini-batch Size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(784, 128),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(64, 32),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(32, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x): #tensor(b, 784)\n",
        "    return self.layers(x) #tensor(b, 10)\n",
        "\n",
        "model = MyModel()\n",
        "tmp = torch.rand(100, 784)\n",
        "output = model(tmp)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMzfOKBfGpG7",
        "outputId": "38a35e03-6e8f-485c-8f29-2c43e98a1ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "import torch.optim as optim\n",
        "\n",
        "model = MyModel()\n",
        "opt = optim.SGD(model.parameters(), lr=0.01)\n",
        "cost_func = nn.CrossEntropyLoss()\n",
        "\n",
        "ds = SmallMNIST(x, y)\n",
        "loader = DataLoader(ds, batch_size=200, shuffle=True)\n",
        "\n",
        "num_epoch = 100\n",
        "for epoch in range(num_epoch):\n",
        "  for i, (bx, by) in enumerate(loader):\n",
        "    output = model(bx)\n",
        "    cost = cost_func(output, by)\n",
        "\n",
        "    if i %100 == 0:\n",
        "      print('Epoch: %d, Iter: %d, Cost: %.4f' % (epoch, i, cost.item()))\n",
        "\n",
        "    cost.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTgBLlAzH_2s",
        "outputId": "739f319e-8f0c-461f-c728-6007d4f1b163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iter: 0, Cost: 2.3296\n",
            "Epoch: 1, Iter: 0, Cost: 2.2985\n",
            "Epoch: 2, Iter: 0, Cost: 2.3120\n",
            "Epoch: 3, Iter: 0, Cost: 2.3000\n",
            "Epoch: 4, Iter: 0, Cost: 2.2924\n",
            "Epoch: 5, Iter: 0, Cost: 2.2948\n",
            "Epoch: 6, Iter: 0, Cost: 2.2875\n",
            "Epoch: 7, Iter: 0, Cost: 2.2933\n",
            "Epoch: 8, Iter: 0, Cost: 2.2927\n",
            "Epoch: 9, Iter: 0, Cost: 2.2957\n",
            "Epoch: 10, Iter: 0, Cost: 2.2868\n",
            "Epoch: 11, Iter: 0, Cost: 2.2910\n",
            "Epoch: 12, Iter: 0, Cost: 2.2962\n",
            "Epoch: 13, Iter: 0, Cost: 2.2930\n",
            "Epoch: 14, Iter: 0, Cost: 2.2848\n",
            "Epoch: 15, Iter: 0, Cost: 2.2803\n",
            "Epoch: 16, Iter: 0, Cost: 2.2830\n",
            "Epoch: 17, Iter: 0, Cost: 2.2795\n",
            "Epoch: 18, Iter: 0, Cost: 2.2774\n",
            "Epoch: 19, Iter: 0, Cost: 2.2786\n",
            "Epoch: 20, Iter: 0, Cost: 2.2707\n",
            "Epoch: 21, Iter: 0, Cost: 2.2802\n",
            "Epoch: 22, Iter: 0, Cost: 2.2675\n",
            "Epoch: 23, Iter: 0, Cost: 2.2774\n",
            "Epoch: 24, Iter: 0, Cost: 2.2662\n",
            "Epoch: 25, Iter: 0, Cost: 2.2592\n",
            "Epoch: 26, Iter: 0, Cost: 2.2670\n",
            "Epoch: 27, Iter: 0, Cost: 2.2604\n",
            "Epoch: 28, Iter: 0, Cost: 2.2605\n",
            "Epoch: 29, Iter: 0, Cost: 2.2641\n",
            "Epoch: 30, Iter: 0, Cost: 2.2524\n",
            "Epoch: 31, Iter: 0, Cost: 2.2508\n",
            "Epoch: 32, Iter: 0, Cost: 2.2603\n",
            "Epoch: 33, Iter: 0, Cost: 2.2413\n",
            "Epoch: 34, Iter: 0, Cost: 2.2316\n",
            "Epoch: 35, Iter: 0, Cost: 2.2381\n",
            "Epoch: 36, Iter: 0, Cost: 2.2267\n",
            "Epoch: 37, Iter: 0, Cost: 2.2218\n",
            "Epoch: 38, Iter: 0, Cost: 2.2087\n",
            "Epoch: 39, Iter: 0, Cost: 2.2092\n",
            "Epoch: 40, Iter: 0, Cost: 2.1955\n",
            "Epoch: 41, Iter: 0, Cost: 2.1917\n",
            "Epoch: 42, Iter: 0, Cost: 2.1650\n",
            "Epoch: 43, Iter: 0, Cost: 2.1786\n",
            "Epoch: 44, Iter: 0, Cost: 2.1602\n",
            "Epoch: 45, Iter: 0, Cost: 2.1214\n",
            "Epoch: 46, Iter: 0, Cost: 2.1134\n",
            "Epoch: 47, Iter: 0, Cost: 2.0877\n",
            "Epoch: 48, Iter: 0, Cost: 2.0691\n",
            "Epoch: 49, Iter: 0, Cost: 2.0276\n",
            "Epoch: 50, Iter: 0, Cost: 1.9435\n",
            "Epoch: 51, Iter: 0, Cost: 1.9246\n",
            "Epoch: 52, Iter: 0, Cost: 1.9509\n",
            "Epoch: 53, Iter: 0, Cost: 1.8861\n",
            "Epoch: 54, Iter: 0, Cost: 1.8844\n",
            "Epoch: 55, Iter: 0, Cost: 1.8552\n",
            "Epoch: 56, Iter: 0, Cost: 1.8658\n",
            "Epoch: 57, Iter: 0, Cost: 1.7790\n",
            "Epoch: 58, Iter: 0, Cost: 1.7050\n",
            "Epoch: 59, Iter: 0, Cost: 1.6446\n",
            "Epoch: 60, Iter: 0, Cost: 1.6740\n",
            "Epoch: 61, Iter: 0, Cost: 1.6565\n",
            "Epoch: 62, Iter: 0, Cost: 1.6048\n",
            "Epoch: 63, Iter: 0, Cost: 1.6328\n",
            "Epoch: 64, Iter: 0, Cost: 1.4758\n",
            "Epoch: 65, Iter: 0, Cost: 1.5004\n",
            "Epoch: 66, Iter: 0, Cost: 1.4988\n",
            "Epoch: 67, Iter: 0, Cost: 1.4930\n",
            "Epoch: 68, Iter: 0, Cost: 1.4035\n",
            "Epoch: 69, Iter: 0, Cost: 1.4710\n",
            "Epoch: 70, Iter: 0, Cost: 1.4138\n",
            "Epoch: 71, Iter: 0, Cost: 1.4727\n",
            "Epoch: 72, Iter: 0, Cost: 1.4002\n",
            "Epoch: 73, Iter: 0, Cost: 1.3745\n",
            "Epoch: 74, Iter: 0, Cost: 1.3271\n",
            "Epoch: 75, Iter: 0, Cost: 1.3228\n",
            "Epoch: 76, Iter: 0, Cost: 1.3399\n",
            "Epoch: 77, Iter: 0, Cost: 1.2947\n",
            "Epoch: 78, Iter: 0, Cost: 1.3439\n",
            "Epoch: 79, Iter: 0, Cost: 1.2658\n",
            "Epoch: 80, Iter: 0, Cost: 1.2220\n",
            "Epoch: 81, Iter: 0, Cost: 1.2267\n",
            "Epoch: 82, Iter: 0, Cost: 1.1827\n",
            "Epoch: 83, Iter: 0, Cost: 1.2602\n",
            "Epoch: 84, Iter: 0, Cost: 1.1940\n",
            "Epoch: 85, Iter: 0, Cost: 1.1904\n",
            "Epoch: 86, Iter: 0, Cost: 1.1188\n",
            "Epoch: 87, Iter: 0, Cost: 1.1349\n",
            "Epoch: 88, Iter: 0, Cost: 1.0583\n",
            "Epoch: 89, Iter: 0, Cost: 1.0454\n",
            "Epoch: 90, Iter: 0, Cost: 1.0390\n",
            "Epoch: 91, Iter: 0, Cost: 0.9986\n",
            "Epoch: 92, Iter: 0, Cost: 1.0264\n",
            "Epoch: 93, Iter: 0, Cost: 1.0150\n",
            "Epoch: 94, Iter: 0, Cost: 0.9465\n",
            "Epoch: 95, Iter: 0, Cost: 0.9163\n",
            "Epoch: 96, Iter: 0, Cost: 0.9973\n",
            "Epoch: 97, Iter: 0, Cost: 0.9608\n",
            "Epoch: 98, Iter: 0, Cost: 0.8909\n",
            "Epoch: 99, Iter: 0, Cost: 0.8813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating on training set\n",
        "num_correct = 0\n",
        "for bx, by in loader:\n",
        "  output = model(bx)\n",
        "  predict = torch.argmax(output, dim=1)\n",
        "  num_correct += (predict == by).sum().item()\n",
        "\n",
        "print('Accuracy: %.2f' % (num_correct / len(ds)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNwE0ESZJAZv",
        "outputId": "de548a7d-433b-4421-aa4b-37db2f544878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating on test set\n",
        "\n",
        "data_test = pd.read_csv('/content/sample_data/mnist_test.csv', header=None).to_numpy()\n",
        "\n",
        "x_test = data_test[:, 1:]\n",
        "y_test = data_test[:, 0]\n",
        "\n",
        "ds_test = SmallMNIST(x_test, y_test)\n",
        "loader_test = DataLoader(ds_test, batch_size=200, shuffle=False)\n"
      ],
      "metadata": {
        "id": "aEsNMw3bKtyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "for bx, by in loader_test:\n",
        "  output = model(bx)\n",
        "  predict = torch.argmax(output, dim=1)\n",
        "  num_correct += (predict == by).sum().item()\n",
        "\n",
        "print('Accuracy on Test: %.2f' % (num_correct / len(ds)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E85J5TViLFTL",
        "outputId": "237f132c-1730-40fd-8488-a471598ca0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test: 0.39\n"
          ]
        }
      ]
    }
  ]
}